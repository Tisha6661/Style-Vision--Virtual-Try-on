{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcd8b080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 'video' to detect pose on video or 'photo' to detect pose on photo: video\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Define a function for pose detection using MediaPipe\n",
    "def detect_pose(image):\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    with mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose_landmarks:\n",
    "        results = pose_landmarks.process(image_rgb)\n",
    "    \n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    return image\n",
    "\n",
    "def detect_pose_on_video():\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        frame_with_pose = detect_pose(frame.copy())\n",
    "\n",
    "        cv2.imshow('Pose Detection', frame_with_pose)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def detect_pose_on_photo(photo_path):\n",
    "    image = cv2.imread(photo_path)\n",
    "\n",
    "    image_with_pose = detect_pose(image)\n",
    "\n",
    "    cv2.imshow('Pose Detection', image_with_pose)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "mode = input(\"Enter 'video' to detect pose on video or 'photo' to detect pose on photo: \")\n",
    "\n",
    "if mode == 'video':\n",
    "    detect_pose_on_video()\n",
    "elif mode == 'photo':\n",
    "    photo_path = input(\"Enter the path to the photo: \")\n",
    "    detect_pose_on_photo(photo_path)\n",
    "else:\n",
    "    print(\"Invalid mode. Please enter either 'video' or 'photo'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d46d8277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose input type (live/photo): live\n",
      "Choose clothing type (upper/lower): upper\n",
      "Enter the URL of the clothing image: https://github.com/Piyusharora2003/label/assets/98682478/30b83daa-786f-4e39-894d-78ed5a77efa6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TISHA\\AppData\\Local\\Temp\\ipykernel_37808\\2968985208.py:138: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  resized_clothing_img = clothing_img.resize((clothing_width, clothing_height), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import requests\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from io import BytesIO\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def estimate_pose(frame):\n",
    "    \n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    with mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose_landmarks:\n",
    "        results = pose_landmarks.process(frame_rgb)\n",
    "\n",
    "    keypoints = []\n",
    "    if results.pose_landmarks:\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            height, width, _ = frame.shape\n",
    "            keypoint = (int(landmark.x * width), int(landmark.y * height))\n",
    "            keypoints.append(keypoint)\n",
    "\n",
    "    return keypoints\n",
    "\n",
    "def download_image(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        return img\n",
    "    else:\n",
    "        print(f\"Error downloading image from {url}\")\n",
    "        return None\n",
    "\n",
    "def resize_and_pad(img, target_size):\n",
    "    img = img.resize(target_size, Image.ANTIALIAS)\n",
    "    return img\n",
    "\n",
    "def overlay_image(background, overlay, keypoints, vêtement_size, clothing_type, is_photo=True):\n",
    "\n",
    "    if len(keypoints) < 3:\n",
    "#         print(\"Not enough keypoints detected. Showing cloth in the middle.\")\n",
    "\n",
    "        overlay_x = (background.width - overlay.width) // 2\n",
    "        overlay_y = (background.height - overlay.height) // 2\n",
    "    else:\n",
    "        if is_photo:\n",
    "            division_point = int(background.height * 0.58) if clothing_type == 'upper' else int(background.height * 0.90)\n",
    "        else:\n",
    "            division_point = int(background.height * 0.80) if clothing_type == 'upper' else int(background.height * 0.90)\n",
    "        \n",
    "        # Ignore the first 7 keypoints, which correspond to the face\n",
    "        body_keypoints = keypoints[7:]\n",
    "\n",
    "        if not body_keypoints:\n",
    "#             print(\"No body keypoints detected. Showing cloth in the middle.\")\n",
    "\n",
    "            overlay_x = (background.width - overlay.width) // 2\n",
    "            overlay_y = (background.height - overlay.height) // 2\n",
    "        else:\n",
    "            center_x = sum(keypoint[0] for keypoint in body_keypoints) // len(body_keypoints)\n",
    "            center_y = sum(keypoint[1] for keypoint in body_keypoints) // len(body_keypoints)\n",
    "\n",
    "            overlay_x = max(0, center_x - overlay.width // 2)\n",
    "            overlay_y = max(0, center_y - overlay.height // 2)\n",
    "\n",
    "            if clothing_type == 'upper':\n",
    "                overlay_y = min(division_point - overlay.height, overlay_y)\n",
    "            else:\n",
    "                overlay_y = min(int((background.height - overlay.height)) + 6, int(overlay_y*1.4)+6)\n",
    "\n",
    "\n",
    "    if overlay.mode != 'RGBA':\n",
    "        overlay = overlay.convert('RGBA')\n",
    "\n",
    "    background.paste(overlay, (overlay_x, overlay_y), overlay)\n",
    "\n",
    "\n",
    "\n",
    "def capture_video(vêtement_img, clothing_type):\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        keypoints = estimate_pose(frame)\n",
    "\n",
    "        frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        overlay_image(frame_pil, vêtement_img, keypoints, vêtement_size, clothing_type, is_photo=False)\n",
    "        frame_rgb = cv2.cvtColor(np.array(frame_pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        cv2.imshow('Virtual Try-On', frame_rgb)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def try_on_photo(photo, vêtement_img, vêtement_size, clothing_type, is_photo=True):\n",
    "    keypoints = estimate_pose(photo)\n",
    "\n",
    "    frame_pil = Image.fromarray(cv2.cvtColor(photo, cv2.COLOR_BGR2RGB))\n",
    "    overlay_image(frame_pil, vêtement_img, keypoints, vêtement_size, clothing_type, is_photo=True)\n",
    "    frame_rgb = cv2.cvtColor(np.array(frame_pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    cv2.imshow('Virtual Try-On', frame_rgb)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def choose_clothing_image():\n",
    "    vêtement_url = input(\"Enter the URL of the clothing image: \")\n",
    "    return vêtement_url\n",
    "\n",
    "def resize_photo_to_screen(photo_path, screen_width, screen_height):\n",
    "    frame = cv2.imread(photo_path)\n",
    "    aspect_ratio = frame.shape[1] / frame.shape[0]\n",
    "    if aspect_ratio > screen_width / screen_height:\n",
    "        resized_frame = cv2.resize(frame, (screen_width, int(screen_width / aspect_ratio)))\n",
    "    else:\n",
    "        resized_frame = cv2.resize(frame, (int(screen_height * aspect_ratio), screen_height))\n",
    "\n",
    "    return resized_frame\n",
    "\n",
    "\n",
    "def resize_clothing_image(clothing_url, screen_width, screen_height):\n",
    "    clothing_img = download_image(clothing_url)\n",
    "    if clothing_img is None:\n",
    "        return None\n",
    "    \n",
    "    clothing_width = int(screen_width / 3.0)\n",
    "    clothing_height = int(screen_height / 2.5)\n",
    "\n",
    "    resized_clothing_img = clothing_img.resize((clothing_width, clothing_height), Image.ANTIALIAS)\n",
    "\n",
    "    return resized_clothing_img\n",
    "\n",
    "\n",
    "# Ask user for input type (live video or photo)\n",
    "input_type = input(\"Choose input type (live/photo): \").lower()\n",
    "\n",
    "# Example usage:\n",
    "screen_width = 800  # Set your screen width\n",
    "screen_height = 780  # Set your screen height\n",
    "\n",
    "\n",
    "if input_type == 'photo':\n",
    "    # Ask user for photo path\n",
    "    photo_path = input(\"Enter the path to the photo: \")\n",
    "    resized_photo = resize_photo_to_screen(photo_path, screen_width, screen_height)\n",
    "\n",
    "    # Ask user for upper or lower body clothing\n",
    "    clothing_type = input(\"Choose clothing type (upper/lower): \").lower()\n",
    "    if clothing_type not in ['upper', 'lower']:\n",
    "        print(\"Invalid clothing type. Defaulting to upper body.\")\n",
    "        clothing_type = 'upper'\n",
    "\n",
    "    # Ask user for clothing image URL\n",
    "    vêtement_url = choose_clothing_image()\n",
    "    resized_clothing_img = resize_clothing_image(vêtement_url, screen_width, screen_height)\n",
    "    \n",
    "    vêtement_size = (resized_clothing_img.width, resized_clothing_img.height)\n",
    "\n",
    "    try_on_photo(resized_photo, resized_clothing_img, vêtement_size, clothing_type, is_photo=True)\n",
    "    \n",
    "elif input_type == 'live':\n",
    "    # Ask user for upper or lower body clothing\n",
    "    clothing_type = input(\"Choose clothing type (upper/lower): \").lower()\n",
    "    if clothing_type not in ['upper', 'lower']:\n",
    "        print(\"Invalid clothing type. Defaulting to upper body.\")\n",
    "        clothing_type = 'upper'\n",
    "\n",
    "        \n",
    "    # Ask user for clothing image URL\n",
    "    vêtement_url = choose_clothing_image()\n",
    "    resized_clothing_img = resize_clothing_image(vêtement_url, screen_width, screen_height)\n",
    "    \n",
    "    vêtement_size = (resized_clothing_img.width, resized_clothing_img.height)\n",
    "\n",
    "    capture_video(resized_clothing_img, clothing_type)\n",
    "    \n",
    "else:\n",
    "    print(\"Invalid input type.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07acca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c9c15b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
